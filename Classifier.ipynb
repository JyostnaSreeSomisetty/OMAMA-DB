{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51db3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:08:15.449469: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Imports and GPU Setup ---\n",
    "import os, glob, random, numpy as np, tensorflow as tf\n",
    "from collections import Counter\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359edb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:08:22.937575: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2025-05-14 11:08:23.151782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:b7:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.39GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2025-05-14 11:08:23.151821: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-05-14 11:08:23.168912: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2025-05-14 11:08:23.168948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2025-05-14 11:08:23.174768: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-14 11:08:23.177284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-14 11:08:23.179561: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2025-05-14 11:08:23.184128: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2025-05-14 11:08:23.185132: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2025-05-14 11:08:23.189833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# Optional: Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception as e:\n",
    "        print(f\"GPU setup error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb6279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Generator ---\n",
    "class NpzDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=32, shuffle=True, target_size=(256, 256)):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.target_size = target_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = [], []\n",
    "        for p, label in zip(batch_paths, batch_labels):\n",
    "            try:\n",
    "                data = np.load(p)\n",
    "                key = 'arr_0' if 'arr_0' in data else 'data' if 'data' in data else None\n",
    "                if key is None:\n",
    "                    print(f\"⚠️ Skipping {p}: no 'arr_0' or 'data' key\")\n",
    "                    continue\n",
    "\n",
    "                img = data[key]\n",
    "\n",
    "                if img.ndim not in [2, 3]:\n",
    "                    print(f\"⚠️ Skipping {p}: 'images' must have 2 or 3 dimensions. Got shape: {img.shape}\")\n",
    "                    continue\n",
    "\n",
    "                if img.ndim == 2:\n",
    "                    img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "                if img.shape[:2] != self.target_size:\n",
    "                    img = tf.image.resize(img, self.target_size).numpy()\n",
    "\n",
    "                X.append(img.astype(np.float32) / 255.0)\n",
    "                y.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Skipping {p}: {str(e)}\")\n",
    "                continue\n",
    "        if not X:\n",
    "            return np.zeros((1, *self.target_size, 1), dtype=np.float32), np.zeros((1,), dtype=np.float32)\n",
    "        return np.stack(X), np.array(y).astype(np.float32)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            zipped = list(zip(self.file_paths, self.labels))\n",
    "            random.shuffle(zipped)\n",
    "            self.file_paths, self.labels = zip(*zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6c053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Utility: Load paths and labels ---\n",
    "def load_paths_and_labels(base_dir):\n",
    "    files, labels = [], []\n",
    "    for label in ['0', '1']:\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        npz_files = glob.glob(os.path.join(label_dir, '*.npz'))\n",
    "        files += npz_files\n",
    "        labels += [int(label)] * len(npz_files)\n",
    "    return files, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6e887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Prepare Data ---\n",
    "train_dir = \"/raid/mpsych/OMAMA/CLASSIFIER/1024_classifier/npz_split_1/train\"\n",
    "val_dir   = \"/raid/mpsych/OMAMA/CLASSIFIER/1024_classifier/npz_split_1/val\"\n",
    "train_paths, train_labels = load_paths_and_labels(train_dir)\n",
    "val_paths, val_labels     = load_paths_and_labels(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b6b01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.5237414044069668, 1: 11.030126849894291}\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Class Weights ---\n",
    "counts = Counter(train_labels)\n",
    "total = sum(counts.values())\n",
    "class_weight = {0: total/(2*counts[0]), 1: total/(2*counts[1])}\n",
    "print(f\"Class weights: {class_weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e636e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Data Generators ---\n",
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (256, 256)\n",
    "train_gen = NpzDataGenerator(train_paths, train_labels, batch_size=BATCH_SIZE, target_size=TARGET_SIZE)\n",
    "val_gen   = NpzDataGenerator(val_paths, val_labels, batch_size=BATCH_SIZE, target_size=TARGET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11e2ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 423,297\n",
      "Trainable params: 422,337\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:09:03.490723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-14 11:09:03.494630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:b7:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.39GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2025-05-14 11:09:03.501976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2025-05-14 11:09:03.502357: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-05-14 11:09:04.368909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-05-14 11:09:04.368960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2025-05-14 11:09:04.368966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2025-05-14 11:09:04.375373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38230 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:b7:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Model ---\n",
    "def build_cnn(input_shape=(256,256,1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 5, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_cnn()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "964fe0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Callbacks ---\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_auc', mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=2, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef1641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/j.somisetty001/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:09:27.611712: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2025-05-14 11:09:27.632799: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245855000 Hz\n",
      "2025-05-14 11:09:29.205736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2025-05-14 11:09:30.359249: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2025-05-14 11:09:31.974799: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2025-05-14 11:09:31.974827: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2025-05-14 11:09:31.975649: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-05-14 11:09:32.020993: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2025-05-14 11:09:33.417658: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2025-05-14 11:09:33.822233: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1422/3913 [=========>....................] - ETA: 26:04 - loss: 0.7101 - accuracy: 0.5111 - auc: 0.5656 - precision: 0.0532 - recall: 0.5798"
     ]
    }
   ],
   "source": [
    "# --- 9. Train ---\n",
    "EPOCHS = 30\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Evaluate ---\n",
    "results = model.evaluate(val_gen, verbose=2)\n",
    "print(f\"Validation results: {dict(zip(model.metrics_names, results))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
